{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a MedNIST Classifier with BentoML\n",
    "\n",
    "This notebook demos the process of packaging up a trained model using BentoML into an artifact which can be run as a local program performing inference, a web service doing the same, and a Docker containerized web service. BentoML provides various ways of deploying models with existing platforms like AWS or Azure but we'll focus on local deployment here since researchers are more likely to do this. This tutorial will train a MedNIST classifier like the [MONAI tutorial here](../../2d_classification/mednist_tutorial.ipynb) and then do the packaging as described in this [BentoML tutorial](https://github.com/bentoml/gallery/blob/master/pytorch/fashion-mnist/pytorch-fashion-mnist.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"monai-weekly[pillow, tqdm]\"\n",
    "%pip install -q bentoml==0.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.6.dev2548\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.8.0+cu128\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: cca0c6d09175a7cf8250cf527092b671af05e303\n",
      "MONAI __file__: /home/<username>/anaconda3/envs/monai/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: 5.4.5\n",
      "Nibabel version: 5.3.2\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.13.1\n",
      "Pillow version: 11.3.0\n",
      "Tensorboard version: 2.20.0\n",
      "gdown version: 5.2.0\n",
      "TorchVision version: 0.23.0+cu128\n",
      "tqdm version: 4.67.1\n",
      "lmdb version: 1.7.5\n",
      "psutil version: 7.1.3\n",
      "pandas version: 2.3.3\n",
      "einops version: 0.8.1\n",
      "transformers version: 4.40.2\n",
      "mlflow version: 3.1.4\n",
      "pynrrd version: 1.1.3\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://monai.readthedocs.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import glob\n",
    "import PIL.Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ignite.engine import Events\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.engines import SupervisedTrainer\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "set_determinism(seed=0)\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "You can specify a directory with the MONAI_DATA_DIRECTORY environment variable.\n",
    "This allows you to save results and reuse downloads.\n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp6_o605sh\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "if directory is not None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "The MedNIST dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions),\n",
    "[the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4),\n",
    "and [the NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
    "\n",
    "The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic)\n",
    "under the Creative Commons [CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "If you use the MedNIST dataset, please acknowledge the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MedNIST.tar.gz: 59.0MB [00:06, 10.3MB/s]                                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-30 22:10:24,636 - INFO - Downloaded: /tmp/tmp6_o605sh/MedNIST.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-30 22:10:24,723 - INFO - Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.\n",
      "2025-11-30 22:10:24,723 - INFO - Writing into directory: /tmp/tmp6_o605sh.\n"
     ]
    }
   ],
   "source": [
    "resource = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\"\n",
    "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
    "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names: ['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n",
      "Label counts: [10000, 8954, 10000, 10000, 10000, 10000]\n",
      "Total image count: 58954\n",
      "Image dimensions: 64 x 64\n"
     ]
    }
   ],
   "source": [
    "subdirs = sorted(glob.glob(f\"{data_dir}/*/\"))\n",
    "\n",
    "class_names = [os.path.basename(sd[:-1]) for sd in subdirs]\n",
    "image_files = [glob.glob(f\"{sb}/*\") for sb in subdirs]\n",
    "\n",
    "image_files_list = sum(image_files, [])\n",
    "image_class = sum(([i] * len(f) for i, f in enumerate(image_files)), [])\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {list(map(len, image_files))}\")\n",
    "print(f\"Total image count: {len(image_class)}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Train\n",
    "\n",
    "Here we'll create a transform sequence and train the network, omitting validation and testing since we know this does indeed work and it's not needed here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        EnsureChannelFirst(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "# just one dataset and loader, we won't bother with validation or testing\n",
    "train_ds = MedNISTDataset(image_files_list, image_class, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=300, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "net = DenseNet121(spatial_dims=2, in_channels=1, out_channels=len(class_names)).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(net.parameters(), 1e-5)\n",
    "max_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 Loss: 0.15544165670871735\n",
      "Epoch 2/5 Loss: 0.09952926635742188\n",
      "Epoch 3/5 Loss: 0.03600173443555832\n",
      "Epoch 4/5 Loss: 0.022248581051826477\n",
      "Epoch 5/5 Loss: 0.02970544993877411\n"
     ]
    }
   ],
   "source": [
    "def _prepare_batch(batch, device, non_blocking):\n",
    "    return tuple(b.to(device) for b in batch)\n",
    "\n",
    "\n",
    "trainer = SupervisedTrainer(device, max_epochs, train_loader, net, opt, loss_function, prepare_batch=_prepare_batch)\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def _print_loss(engine):\n",
    "    print(f\"Epoch {engine.state.epoch}/{engine.state.max_epochs} Loss: {engine.state.output[0]['loss']}\")\n",
    "\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network will be saved out here as a Torchscript object but this isn't necessary as we'll see later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.script(net).save(\"classifier.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BentoML Setup\n",
    "\n",
    "BentoML provides it's platform through an API to wrap service requests as method calls. This is obviously similar to how Flask works (which is one of the underlying technologies used here), but on top of this is provided various facilities for storing the network (artifacts), handling the IO component of requests, and caching data. What we need to provide is a script file to represent the services we want, BentoML will take this with the artifacts we provide and store this in a separate location which can be run locally as well as uploaded to a server (sort of like Docker registries). \n",
    "\n",
    "The script below will create our API which includes MONAI code. The transform sequence needs a special read Transform to turn a data stream into an image, but otherwise the code like what was used above for training. The network is stored as an artifact which in practice is the stored weights in the BentoML bundle. This is loaded at runtime automatically, but instead we could load the Torchscript model instead if we wanted to, in particular if we wanted an API that didn't rely on MONAI code. \n",
    "\n",
    "The script needs to be written out to a file first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mednist_classifier_bentoml.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_classifier_bentoml.py\n",
    "\n",
    "from typing import BinaryIO, List\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    Compose,\n",
    "    Transform,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "\n",
    "import bentoml\n",
    "from bentoml.frameworks.pytorch import PytorchModelArtifact\n",
    "from bentoml.adapters import FileInput, JsonOutput\n",
    "from bentoml.utils import cached_property\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]\n",
    "\n",
    "\n",
    "class LoadStreamPIL(Transform):\n",
    "    \"\"\"Load an image file from a data stream using PIL.\"\"\"\n",
    "\n",
    "    def __init__(self, mode=None):\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, stream):\n",
    "        img = Image.open(stream)\n",
    "\n",
    "        if self.mode is not None:\n",
    "            img = img.convert(mode=self.mode)\n",
    "\n",
    "        return np.array(img)\n",
    "\n",
    "\n",
    "@bentoml.env(pip_packages=[\"torch\", \"numpy\", \"monai\", \"pillow\"])\n",
    "@bentoml.artifacts([PytorchModelArtifact(\"classifier\")])\n",
    "class MedNISTClassifier(bentoml.BentoService):\n",
    "    @cached_property\n",
    "    def transform(self):\n",
    "        return Compose([LoadStreamPIL(\"L\"), EnsureChannelFirst(channel_dim=\"no_channel\"), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    @bentoml.api(input=FileInput(), output=JsonOutput(), batch=True)\n",
    "    def predict(self, file_streams: List[BinaryIO]) -> List[str]:\n",
    "        img_tensors = list(map(self.transform, file_streams))\n",
    "        batch = torch.stack(img_tensors).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.artifacts.classifier(batch)\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        return [MEDNIST_CLASSES[oc] for oc in output_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the script is loaded and the classifier artifact is packed with the network's state. This is then saved to a repository directory on the local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-30 22:18:49,627] WARNING - Python 3.9.12 found in current environment is not officially supported by BentoML. The docker base image used is'bentoml/model-server:0.13.1' which will use conda to install Python 3.9.12 in the build process. Supported Python versions are: f3.6, 3.7, 3.8\n",
      "[2025-11-30 22:18:49,628] WARNING - BentoML by default does not include spacy and torchvision package when using PytorchModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2025-11-30 22:18:50,510] INFO - BentoService bundle 'MedNISTClassifier:20251130221849_276B39' saved to: /home/esl/bentoml/repository/MedNISTClassifier/20251130221849_276B39\n",
      "/home/esl/bentoml/repository/MedNISTClassifier/20251130221849_276B39\n"
     ]
    }
   ],
   "source": [
    "from mednist_classifier_bentoml import MedNISTClassifier  # noqa: E402\n",
    "\n",
    "bento_svc = MedNISTClassifier()\n",
    "bento_svc.pack(\"classifier\", net.cpu().eval())\n",
    "\n",
    "saved_path = bento_svc.save()\n",
    "\n",
    "print(saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the contents of this repository, which includes code and setup scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 48\n",
      "-rwxrw-r-- 1 esl esl 3170 十一 30 22:18 bentoml-init.sh\n",
      "-rw-rw-r-- 1 esl esl  829 十一 30 22:18 bentoml.yml\n",
      "-rwxrw-r-- 1 esl esl  841 十一 30 22:18 docker-entrypoint.sh\n",
      "-rw-rw-r-- 1 esl esl 1593 十一 30 22:18 Dockerfile\n",
      "-rw-rw-r-- 1 esl esl 3317 十一 30 22:18 docs.json\n",
      "-rw-rw-r-- 1 esl esl   49 十一 30 22:18 environment.yml\n",
      "-rw-rw-r-- 1 esl esl   72 十一 30 22:18 MANIFEST.in\n",
      "drwxrwxr-x 4 esl esl 4096 十一 30 22:18 MedNISTClassifier\n",
      "-rw-rw-r-- 1 esl esl    6 十一 30 22:18 python_version\n",
      "-rw-rw-r-- 1 esl esl  298 十一 30 22:18 README.md\n",
      "-rw-rw-r-- 1 esl esl   70 十一 30 22:18 requirements.txt\n",
      "-rw-rw-r-- 1 esl esl 1691 十一 30 22:18 setup.py\n"
     ]
    }
   ],
   "source": [
    "!ls -l {saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository can be run like a stored program where we invoke it by name and the API name (\"predict\") we want to use and provide the inputs as a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-30 22:18:55,565] INFO - Getting latest version MedNISTClassifier:20251130221849_276B39\n",
      "[2025-11-30 22:18:59,557] WARNING - Python 3.9.12 found in current environment is not officially supported by BentoML. The docker base image used is'bentoml/model-server:0.13.1' which will use conda to install Python 3.9.12 in the build process. Supported Python versions are: f3.6, 3.7, 3.8\n",
      "[2025-11-30 22:18:59,611] WARNING - BentoML by default does not include spacy and torchvision package when using PytorchModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2025-11-30 22:18:59,632] INFO - {'service_name': 'MedNISTClassifier', 'service_version': '20251130221849_276B39', 'api': 'predict', 'task': {'data': {'uri': 'file:///tmp/tmp6_o605sh/MedNIST/AbdomenCT/008691.jpeg', 'name': '008691.jpeg'}, 'task_id': '4d0bf8d8-f9fb-411f-b0ff-22b290d4d848', 'cli_args': ('--input-file', '/tmp/tmp6_o605sh/MedNIST/AbdomenCT/008691.jpeg'), 'inference_job_args': {}}, 'result': {'data': '\"HeadCT\"', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '4d0bf8d8-f9fb-411f-b0ff-22b290d4d848'}\n",
      "\"HeadCT\"\n"
     ]
    }
   ],
   "source": [
    "!bentoml run MedNISTClassifier:latest predict --input-file {image_files[0][0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The service can also be run off of a Flask web server. The following script starts the service, waits for it to get going, uses curl to send the test file as a POST request to get a prediction, then kill the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試圖片: /tmp/tmp6_o605sh/MedNIST/AbdomenCT/008691.jpeg\n",
      "正在啟動 Server (Port 3000)...\n",
      "發送預測請求...\n",
      "Server 已關閉。\n",
      "--------------------------------\n",
      "Prediction: An error has occurred in BentoML user code when handling this request, find the error details in server logs\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {image_files[0][0]}\n",
    "# 取得測試圖片路徑\n",
    "test_file=$1\n",
    "echo \"測試圖片: $test_file\"\n",
    "\n",
    "# 1. 啟動 BentoML Server，改用 Port 3000\n",
    "# 使用 --port=3000 避開你的 8000\n",
    "echo \"正在啟動 Server (Port 3000)...\"\n",
    "bentoml serve --port=3000 MedNISTClassifier:latest &> server_log.txt &\n",
    "\n",
    "# 記錄 Server 的 Process ID (PID) 以便稍後關閉\n",
    "lastpid=$!\n",
    "\n",
    "# 2. 等待 Server 啟動 (給它 10-15 秒，避免太快發送請求)\n",
    "sleep 15\n",
    "\n",
    "# 3. 發送測試請求 (curl)\n",
    "# 注意：網址也要改成 3000\n",
    "echo \"發送預測請求...\"\n",
    "result=$(curl -s -X POST \"http://127.0.0.1:3000/predict\" -F image=@$test_file)\n",
    "\n",
    "# 4. 關閉 Server\n",
    "kill $lastpid\n",
    "echo \"Server 已關閉。\"\n",
    "\n",
    "# 5. 顯示結果\n",
    "echo \"--------------------------------\"\n",
    "echo \"Prediction: $result\"\n",
    "echo \"--------------------------------\"\n",
    "\n",
    "# 如果結果是空的，印出 Server log 幫助除錯\n",
    "if [ -z \"$result\" ]; then\n",
    "    echo \"錯誤：沒有收到預測結果，Server 可能啟動失敗。Log 如下：\"\n",
    "    cat server_log.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The service can be packaged as a Docker container to be started elsewhere as a server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-30 22:22:21,395] INFO - Getting latest version MedNISTClassifier:20251130221849_276B39\n",
      "\u001b[39mFound Bento: /home/esl/bentoml/repository/MedNISTClassifier/20251130221849_276B39\u001b[0m\n",
      "Containerizing MedNISTClassifier:20251130221849_276B39 with local YataiService and docker daemon from local environment-[2025-11-30 22:22:21,418] ERROR - RPC ERROR ContainerizeBento: Docker is required for this deployment. Please visit www.docker.com for instructions\n",
      "Error: \u001b[31mbentoml-cli containerize failed: Failed to containerize MedNISTClassifier:20251130221849_276B39 - INTERNAL:Docker is required for this deployment. Please visit www.docker.com for instructions\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml containerize MedNISTClassifier:latest -t mednist-classifier:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY        TAG        IMAGE ID       CREATED         SIZE\n",
      "tag-twin-api      latest     1d0b67c5072e   2 weeks ago     1.12GB\n",
      "redis             7-alpine   13105d2858de   3 weeks ago     41.4MB\n",
      "postgis/postgis   16-3.4     06287eb8e12c   13 months ago   609MB\n"
     ]
    }
   ],
   "source": [
    "!docker image ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-30 22:22:24,890] WARNING - BentoML by default does not include spacy and torchvision package when using PytorchModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "from mednist_classifier_bentoml import MedNISTClassifier\n",
    "\n",
    "# 1. 準備圖片\n",
    "test_image_path = image_files[0][0] \n",
    "test_image = PIL.Image.open(test_image_path).convert(\"L\")\n",
    "\n",
    "# 2. 載入 BentoML 服務 (在記憶體中執行，不需要 Port)\n",
    "bento_service = MedNISTClassifier()\n",
    "bento_service.pack(\"classifier\", net.cpu().eval())\n",
    "\n",
    "# 3. 執行預測\n",
    "with open(test_image_path, \"rb\") as f:\n",
    "    prediction = bento_service.predict([f])\n",
    "\n",
    "# 4. 畫圖 (報告要的證明)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(np.array(test_image), cmap=\"gray\")\n",
    "plt.title(f\"BentoML Test Result\\nPrediction: {prediction[0]}\", \n",
    "          fontsize=14, color=\"blue\", fontweight=\"bold\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup data directory\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
